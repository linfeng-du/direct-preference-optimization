Creating trainer on process 0 with world size 1
> /home/mila/k/klissarm/direct-preference-optimization/trainers.py(202)__init__()
-> if self.config.use_hnet and not self.config.train_reward :
*** AttributeError: 'int' object has no attribute 'use_hnet'
0
Error executing job with overrides: ['model=pythia28', 'datasets=[hh]', 'loss=sft', 'exp_name=anthropic_dpo_pythia28', 'gradient_accumulation_steps=2', 'batch_size=64', 'eval_batch_size=32', 'trainer=FSDPTrainer', 'sample_during_eval=false', 'model.fsdp_policy_mp=bfloat16']
Traceback (most recent call last):
  File "/home/mila/k/klissarm/direct-preference-optimization/train.py", line 242, in main
    worker_main(0, 1, config, policy, reference_model)
  File "/home/mila/k/klissarm/direct-preference-optimization/train.py", line 96, in worker_main
    trainer = TrainerClass(policy, config, config.seed, config.local_run_dir, reference_model=reference_model, rank=rank, world_size=world_size,hnet_controller = controller)
  File "/home/mila/k/klissarm/direct-preference-optimization/trainers.py", line 848, in __init__
    super().__init__(policy, config, seed, run_dir, reference_model, rank, world_size)
  File "/home/mila/k/klissarm/direct-preference-optimization/trainers.py", line 202, in __init__
    if self.config.use_hnet and not self.config.train_reward :
  File "/home/mila/k/klissarm/direct-preference-optimization/trainers.py", line 202, in __init__
    if self.config.use_hnet and not self.config.train_reward :
  File "/cvmfs/ai.mila.quebec/apps/x86_64/debian/python/3.10/lib/python3.10/bdb.py", line 90, in trace_dispatch
    return self.dispatch_line(frame)
  File "/cvmfs/ai.mila.quebec/apps/x86_64/debian/python/3.10/lib/python3.10/bdb.py", line 115, in dispatch_line
    if self.quitting: raise BdbQuit
bdb.BdbQuit

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
